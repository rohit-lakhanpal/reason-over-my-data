{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Evaluation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Ensure that the required environment variables are set.\n",
    "\n",
    "### 1a. Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install python-dotenv --quiet\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Install pre-requisite libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install requests beautifulsoup4 markdownify urllib3 --quiet\n",
    "! pip install ipykernel --quiet\n",
    "! pip install ipywidgets --quiet\n",
    "! pip install llama-index llama-index-vector-stores-azureaisearch --quiet\n",
    "! pip install azure-search-documents --quiet\n",
    "! pip install azure-data-tables --quiet\n",
    "! pip install spacy --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Enable Async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NESTED ASYNCIO LOOP NEEDED TO RUN ASYNC IN A NOTEBOOK\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d. Create JSONL workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder_path = 'evaluation_output'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "llama_path = f'{folder_path}/llama_eval'\n",
    "os.makedirs(llama_path, exist_ok=True)\n",
    "pf_path = f'{folder_path}/pf_eval'\n",
    "os.makedirs(pf_path, exist_ok=True)\n",
    "pf_merged_path = f'{folder_path}/pf_merged_eval'\n",
    "os.makedirs(pf_merged_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load, Fetch and Evaluate Inventory Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Load Inventory Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../utilities/storeInventory.py\n",
    "%run -i ../utilities/fetchAndIngest.py\n",
    "%run -i ../utilities/jsonlConverter.py\n",
    "\n",
    "# Print the number of rows in the inventory table\n",
    "print(f'The inventory table contains {get_inventory_table_count()} rows.')\n",
    "\n",
    "documents=[]\n",
    "\n",
    "# Fetch rows 100 and 110 of the table & ingest the url\n",
    "for inventory in get_inventory_entities_by_page(page_size=50, page_number=1):\n",
    "    print(f'Fetching {inventory['Url']} ...')\n",
    "    document = generate_llama_document(fetch_document(inventory['Url']))\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. (Optional) Evaluate the first inventory item\n",
    "\n",
    "This creates an evaluation file in the JSONL format that will be consumed by Llama Index & Prompt Flow's evaluation flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_dataset.generator import RagDatasetGenerator\n",
    "from IPython.display import Markdown, JSON \n",
    "\n",
    "# document = documents[0]\n",
    "# print(f'Evaluating {inventory['Url']} with id {document.doc_id}...')\n",
    "# rag_data_generator = RagDatasetGenerator.from_documents(\n",
    "#     documents=[document], \n",
    "#     show_progress=True,\n",
    "#     llm=get_aoai()['llm'],\n",
    "#     num_questions_per_chunk=1\n",
    "# )\n",
    "# dataset = rag_data_generator.generate_dataset_from_nodes()\n",
    "# input_file = f\"{llama_path}/{document.doc_id}.jsonl\"\n",
    "# output_file = f\"{pf_path}/{document.doc_id}.jsonl\"\n",
    "# dataset.save_json(input_file)\n",
    "# convert_llama_to_pf_jsonl(input_file, output_file)\n",
    "# print(f'JSONL evaluation for LlamaIndex created at {input_file}')\n",
    "# print(f'JSONL evaluation for PromptFlow created at {output_file}')\n",
    "# display(JSON(f\"{dataset.json()}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. (Optional) Evaluate the inventory list\n",
    "\n",
    "This creates an evaluation file in the JSONL format that will be consumed by Llama Index & Prompt Flow's evaluation flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for document in documents:\n",
    "    counter = counter + 1\n",
    "    rag_data_generator = RagDatasetGenerator.from_documents(\n",
    "        documents=[document], \n",
    "        show_progress=True,\n",
    "        llm=get_aoai()['llm'],\n",
    "        num_questions_per_chunk=2\n",
    "    )    \n",
    "    dataset = rag_data_generator.generate_dataset_from_nodes()\n",
    "    input_file = f\"{llama_path}/{document.doc_id}.jsonl\"\n",
    "    output_file = f\"{pf_path}/{document.doc_id}.jsonl\"\n",
    "    dataset.save_json(input_file)\n",
    "    convert_llama_to_pf_jsonl(input_file, output_file)\n",
    "    print(f'[{counter}]: JSONL evaluation for LlamaIndex created at {input_file}')\n",
    "    print(f'[{counter}]: JSONL evaluation for PromptFlow created at {output_file}')   \n",
    "    # display(JSON(f\"{dataset.json()}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. Merge all jsonl files into 1 single file\n",
    "\n",
    "This merged file will be used as test data for our evaluation flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../utilities/jsonlConverter.py\n",
    "merge_jsonl_files(pf_path, pf_merged_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
